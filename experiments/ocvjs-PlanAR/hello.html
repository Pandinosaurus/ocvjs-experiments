<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Hello OpenCV.js</title>
</head>
<body>
<h2>Hello OpenCV.js</h2>
<p id="status">OpenCV.js is loading...</p>
<div>
    <div class="control"><button id="startAndStop">Start</button></div>
</div>
<div>
  <video id="videoInput" width=320 height=240 hidden></video>
  <div class="inputoutput">
    <canvas id="canvasReference" ></canvas>
    <div class="caption">imageSrc </div>
  </div>
  <div class="inputoutput">
    <canvas id="canvasOutput" ></canvas>
    <div class="caption">canvasOutput</div>
  </div>
  <img id="reference" src="data/magazine.jpg" hidden/> 
</div>
<script type="text/javascript">
// Button to start and stop the video
var startAndStop = document.getElementById('startAndStop');
startAndStop.addEventListener('click', () => {
    if (!streaming) {
        startCamera('qvga');
    } else {
        stopCamera();
    }
});

// Video input handling (HTML5)
var video = document.getElementById('videoInput');
var streaming = false;
function startCamera(resolution) {
    const constraints = {
        'qvga': {width: {exact: 320}, height: {exact: 240}},
        'vga': {width: {exact: 640}, height: {exact: 480}}
    };

    let videoConstraint = constraints[resolution];
    if (!videoConstraint) {
        videoConstraint = true;
    }
    navigator.mediaDevices.getUserMedia({video: videoConstraint, audio: false})
        .then(function(stream) {
            video.srcObject = stream;
            video.play();
            streaming = true;
            startAndStop.innerText = 'Stop';
            process();
        })
        .catch(function(err) {
            console.log('Camera Error: ' + err.name + ' ' + err.message);
        });
};
function stopCamera() {
    if (video) {
        video.pause();
        video.srcObject = null;
        streaming = false;
        startAndStop.innerText = 'Start';
    }
};

// Process images captured with the video
var init = false;
var reference, 
    reference_keypoints, 
    reference_descriptors, 
    referenceObject, 
    reference_corners;
var scene, 
    scene_keypoints, 
    scene_descriptors, 
    sceneObject;

function detectAndComputeKeypointsOnImageObject(imageObject, features=4000)
{
    // Orb keypoints detector & descriptor (extractor)
    var orb = new cv.ORB(features, //nb features 
                            1.2, //scale decimation between 2 level of the pyramid
                            8, //nb of levels (scales) in the pyramid
                            10, //offset from image border
                            1, //level of input image in the pyramid, higher levels are obtained by uspamling
                            ); 

    // Let's work on a temporary matrix
    var tmp = new cv.Mat();

    // Return if image has not been read or allocated
    if(imageObject['img'].empty())
    { 
        tmp.delete(); 
        return; 
    }

    // Convert image in RGB color space, assuming it is in RGBA
    try
    {
        cv.cvtColor(imageObject['img'], 
                    tmp, 
                    cv.COLOR_RGBA2GRAY);
    }
    catch(err)
    {
        console.log(err);
        tmp = imageObject['img'];
    }
    if(tmp.empty())
    { 
        tmp.delete(); 
        return; 
    }

    // Find keypoints
    orb.detect(tmp, 
                imageObject['keypoints'], 
                new cv.Mat());
    if(imageObject['keypoints'].size() == 0)
    { 
        tmp.delete(); 
        return; 
    }

    // Compute descriptors
    orb.compute(tmp, 
                imageObject['keypoints'], 
                imageObject['descriptors']);
    imageObject['descriptors'].convertTo(imageObject['descriptors'], cv.CV_32F); //for flann based
    
    if(imageObject['keypoints'].size() == 0)
    { 
        tmp.delete(); 
        return; 
    }
    
    // Clear tmp memory and return
    orb.delete();
    tmp.delete(); 
    return;
};

// Perform a ratio test on matched keypoints
// Return an object containing two matrix.
// Each matrix represent a list of points
// Respectively for reference and scene images
// 
// Idea :
// Construct matrix with maximum number of rows
// After filling them with good match, we will
// just have to crop the matrix row wise
// using the number of good matches :D
// Note for future : think to add an early stop
// in ratio test calculation after studying some
// statistics on accuracy / number of matches used
function ratioTestToMat(imageObjectReference, imageObjectScene, kmatches, k=1, maxDist=9999, ratio=0.85)
{
    var PointReference = new cv.Mat(kmatches.size(), 
                                    1,
                                    cv.CV_32FC2);
    var PointScene     = new cv.Mat(kmatches.size(), 
                                    1,
                                    cv.CV_32FC2);

    var row             = 0; // nb of rows <=> nb good matches
    var distance_first  = 9999;
    var distance_second = 9999;
    var referenceIdx    = -1;
    var sceneIdx        = -1;

    if(k<=0) { 
        return [new cv.Mat(), new cv.Mat()]; 
    }
    else if(k==1) {
        for(var i = 0; i < kmatches.size(); i++) {
            distance_first = kmatches.get(i).get(0)['distance'];
            if(distance_first < maxDist) {
                referenceIdx = kmatches.get(i).get(0).trainIdx;
                PointReference.floatPtr(row, 0)[0] = 
                    imageObjectReference['keypoints'].get(referenceIdx)['pt']['x'];
                PointReference.floatPtr(row, 0)[1] = 
                    imageObjectReference['keypoints'].get(referenceIdx)['pt']['y'];
                
                sceneIdx = kmatches.get(i).get(0).queryIdx;
                PointScene.floatPtr(row, 0)[0] = 
                    imageObjectScene['keypoints'].get(sceneIdx)['pt']['x'];
                PointScene.floatPtr(row, 0)[1] = 
                    imageObjectScene['keypoints'].get(sceneIdx)['pt']['y'];
                
                row += 1;
            }
        }
    }
    else if(k>=2){
        for(var i = 0; i < kmatches.size(); i++) {
            distance_first = kmatches.get(i).get(0)['distance'];
            distance_second = kmatches.get(i).get(1)['distance'];
            if(distance_first < maxDist && distance_first < ratio*distance_second) {
                referenceIdx = kmatches.get(i).get(0).trainIdx;
                PointReference.floatPtr(row, 0)[0] = imageObjectReference['keypoints'].get(referenceIdx)['pt']['x'];
                PointReference.floatPtr(row, 0)[1] = imageObjectReference['keypoints'].get(referenceIdx)['pt']['y'];
                
                sceneIdx = kmatches.get(i).get(0).queryIdx;
                PointScene.floatPtr(row, 0)[0] = imageObjectScene['keypoints'].get(sceneIdx)['pt']['x'];
                PointScene.floatPtr(row, 0)[1] = imageObjectScene['keypoints'].get(sceneIdx)['pt']['y'];
                
                row += 1;
            }
        }
        
    }
    
    // Get roi
    var rect = new cv.Rect(0,0,1,row);
    var out_PointReference = new cv.Mat();
    out_PointReference = PointReference.roi(rect);
    var out_PointScene = new cv.Mat();
    out_PointScene = PointScene.roi(rect);

    // Clean up
    delete row;
    delete distance_first;
    delete distance_second;
    delete referenceIdx;
    delete sceneIdx;
    delete rect;
    PointReference.delete();
    PointScene.delete();

    // Return good matches
    return [out_PointReference, out_PointScene];
};


function matchKeypoints(imageObjectScene, imageObjectReference)
{
    // Construct FLANN based matcher and a structure for the k-matches
    var matcher = new cv.DescriptorMatcher("FlannBased");
    var kmatches = new cv.DMatchVectorVector();
    
    // match - slow
    var k = 1; // nb of neighbors
    matcher.knnMatch(imageObjectScene['descriptors'], 
                     imageObjectReference['descriptors'], 
                     kmatches,
                     k); 

    // Get good matches after ratio test
    var out_Points = ratioTestToMat(imageObjectReference, 
                                    imageObjectScene, 
                                    kmatches, 
                                    k, 
                                    300);

    // Clean the mess
    matcher.delete();
    kmatches.delete();
    delete k;

    // Return
    return out_Points;
}

// Find homography
function getHomographyBetweenImageObjects(imageObjectScene, imageObjectReference)
{
    var H = new cv.Mat();

    // Match - slow
    var out_Points = matchKeypoints(imageObjectScene, 
                                    imageObjectReference);

    // Find Homography if enough points do match
    if(out_Points[0].rows > imageObjectReference['keypoints'].size()/8){
        var H = cv.findHomography(out_Points[0], 
                                    out_Points[1],
                                    cv.RANSAC); //cv.RHO (prosac)
    }
    
    out_Points[0].delete();
    out_Points[1].delete(); 

    return H;

}

function drawBoxOnImageObject(imageObject, corners)
{
    //-- Draw lines between the corners
    var color = new cv.Scalar(125, 255, 0, 255);
    cv.line(imageObject['img'], 
            new cv.Point(corners.floatPtr(0,0)[0], 
                            corners.floatPtr(0,0)[1]),
            new cv.Point(corners.floatPtr(1,0)[0], 
                            corners.floatPtr(1,0)[1]), 
            color,
            4 );
    cv.line(imageObject['img'], 
            new cv.Point(corners.floatPtr(1,0)[0], 
                            corners.floatPtr(1,0)[1]),
            new cv.Point(corners.floatPtr(2,0)[0], 
                            corners.floatPtr(2,0)[1]), 
            color,
            4 );
    cv.line(imageObject['img'], 
            new cv.Point(corners.floatPtr(2,0)[0], 
                            corners.floatPtr(2,0)[1]),
            new cv.Point(corners.floatPtr(3,0)[0], 
                            corners.floatPtr(3,0)[1]), 
            color,
            4 );
    cv.line(imageObject['img'], 
            new cv.Point(corners.floatPtr(3,0)[0], 
                            corners.floatPtr(3,0)[1]),
            new cv.Point(corners.floatPtr(0,0)[0], 
                            corners.floatPtr(0,0)[1]), 
            color,
            4 );
    delete color;
}

function process(){
  if(streaming){
      if(!init){
          // Reference
          reference = cv.imread(document.getElementById('reference'));
          reference_keypoints = new cv.KeyPointVector();
          reference_descriptors = new cv.Mat();
          referenceObject = { img: reference, 
                              keypoints: reference_keypoints,
                              descriptors: reference_descriptors };
          reference_corners_mat = new cv.Mat(4,1, cv.CV_32FC2);
          reference_corners_mat.floatPtr(0, 0)[0] = 0; //(row, col)[channel]
          reference_corners_mat.floatPtr(0, 0)[1] = 0;
          reference_corners_mat.floatPtr(1, 0)[0] = reference.cols;
          reference_corners_mat.floatPtr(1, 0)[1] = 0;
          reference_corners_mat.floatPtr(2, 0)[0] = reference.cols;
          reference_corners_mat.floatPtr(2, 0)[1] = reference.rows;
          reference_corners_mat.floatPtr(3, 0)[0] = 0;
          reference_corners_mat.floatPtr(3, 0)[1] = reference.rows;
          detectAndComputeKeypointsOnImageObject(referenceObject, 3000)

          // Frame
          scene = new cv.Mat(video.height, video.width, cv.CV_8UC4);
          sceneSmall = new cv.Mat(240, 320, cv.CV_8UC4);
          scene_keypoints = new cv.KeyPointVector();
          scene_descriptors = new cv.Mat();
          sceneObject = { imgReal: scene, 
                          img: sceneSmall,
                          keypoints: scene_keypoints,
                          descriptors: scene_descriptors };
          
          init = true;
      }

      let cap = new cv.VideoCapture(video);
      cap.read(sceneObject['img']);
      cv.resize(sceneObject['img'], sceneObject['img'], new cv.Size(320, 240));
      detectAndComputeKeypointsOnImageObject(sceneObject, 3000);
      var H = getHomographyBetweenImageObjects(sceneObject, referenceObject);
      var scene_corners = new cv.Mat();
      if(!H.empty()){
        cv.perspectiveTransform(reference_corners_mat, scene_corners, H);
      }
      drawBoxOnImageObject(sceneObject, scene_corners);
      cv.imshow('canvasOutput', sceneObject['img']);
      cv.imshow('canvasReference', referenceObject['img']);
  }
  setTimeout(process, 1000/60);
}

function onOpenCvReady() {
  document.getElementById('status').innerHTML = 'OpenCV.js is ready.';
}
</script>
<script async src="opencv/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
</body>
</html>